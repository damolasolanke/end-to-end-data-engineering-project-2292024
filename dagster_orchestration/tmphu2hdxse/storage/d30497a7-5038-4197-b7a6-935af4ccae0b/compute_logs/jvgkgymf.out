2024-03-04 02:43:46 [46mplatform[0m > Docker volume job log path: /tmp/workspace/2/0/logs.log
2024-03-04 02:43:46 [46mplatform[0m > Executing worker wrapper. Airbyte version: 0.50.54
2024-03-04 02:43:46 [46mplatform[0m > Attempt 0 to save workflow id for cancellation
2024-03-04 02:43:46 [46mplatform[0m > start sync worker. job id: 2 attempt id: 0
2024-03-04 02:43:46 [46mplatform[0m > 
2024-03-04 02:43:46 [46mplatform[0m > ----- START REPLICATION -----
2024-03-04 02:43:46 [46mplatform[0m > 
2024-03-04 02:43:46 [46mplatform[0m > Running destination...
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_LIMIT: '2.0'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_LIMIT: '2.0'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_LIMIT: '2.0'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_LIMIT: '2.0'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_REQUEST: '0.1'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SIDECAR_KUBE_CPU_REQUEST: '0.1'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_REQUEST: '0.1'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable SOCAT_KUBE_CPU_REQUEST: '0.1'
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable LAUNCHDARKLY_KEY: ''
2024-03-04 02:43:46 [46mplatform[0m > Using default value for environment variable LAUNCHDARKLY_KEY: ''
2024-03-04 02:43:46 [46mplatform[0m > Checking if airbyte/destination-bigquery:2.4.10 exists...
2024-03-04 02:43:46 [46mplatform[0m > Checking if airbyte/source-postgres:3.3.11 exists...
2024-03-04 02:43:46 [46mplatform[0m > airbyte/destination-bigquery:2.4.10 was found locally.
2024-03-04 02:43:46 [46mplatform[0m > airbyte/source-postgres:3.3.11 was found locally.
2024-03-04 02:43:47 [46mplatform[0m > Creating docker container = source-postgres-read-2-0-kuaxa with resources io.airbyte.config.ResourceRequirements@46754312[cpuRequest=1,cpuLimit=2,memoryRequest=1Gi,memoryLimit=2Gi,additionalProperties={}] and allowedHosts io.airbyte.config.AllowedHosts@54587bf2[hosts=[localhost, *.datadoghq.com, *.datadoghq.eu, *.sentry.io],additionalProperties={}]
2024-03-04 02:43:47 [46mplatform[0m > Creating docker container = destination-bigquery-write-2-0-xjvjj with resources io.airbyte.config.ResourceRequirements@30cf50ce[cpuRequest=1,cpuLimit=2,memoryRequest=1Gi,memoryLimit=2Gi,additionalProperties={}] and allowedHosts null
2024-03-04 02:43:47 [46mplatform[0m > Preparing command: docker run --rm --init -i -w /data/2/0 --log-driver none --name destination-bigquery-write-2-0-xjvjj --network host -v airbyte_workspace:/data -v /tmp/airbyte_local:/local -e DEPLOYMENT_MODE=OSS -e WORKER_CONNECTOR_IMAGE=airbyte/destination-bigquery:2.4.10 -e AUTO_DETECT_SCHEMA=true -e LAUNCHDARKLY_KEY= -e SOCAT_KUBE_CPU_REQUEST=0.1 -e SOCAT_KUBE_CPU_LIMIT=2.0 -e FIELD_SELECTION_WORKSPACES= -e USE_STREAM_CAPABLE_STATE=true -e WORKER_ENVIRONMENT=DOCKER -e AIRBYTE_ROLE=dev -e APPLY_FIELD_SELECTION=false -e WORKER_JOB_ATTEMPT=0 -e OTEL_COLLECTOR_ENDPOINT=http://host.docker.internal:4317 -e FEATURE_FLAG_CLIENT=config -e AIRBYTE_VERSION=0.50.54 -e WORKER_JOB_ID=2 --cpus=2 --memory-reservation=1Gi --memory=2Gi airbyte/destination-bigquery:2.4.10 write --config destination_config.json --catalog destination_catalog.json
2024-03-04 02:43:47 [46mplatform[0m > Preparing command: docker run --rm --init -i -w /data/2/0 --log-driver none --name source-postgres-read-2-0-kuaxa -e CONCURRENT_SOURCE_STREAM_READ=false --network host -v airbyte_workspace:/data -v /tmp/airbyte_local:/local -e DEPLOYMENT_MODE=OSS -e WORKER_CONNECTOR_IMAGE=airbyte/source-postgres:3.3.11 -e AUTO_DETECT_SCHEMA=true -e LAUNCHDARKLY_KEY= -e SOCAT_KUBE_CPU_REQUEST=0.1 -e SOCAT_KUBE_CPU_LIMIT=2.0 -e FIELD_SELECTION_WORKSPACES= -e USE_STREAM_CAPABLE_STATE=true -e WORKER_ENVIRONMENT=DOCKER -e AIRBYTE_ROLE=dev -e APPLY_FIELD_SELECTION=false -e WORKER_JOB_ATTEMPT=0 -e OTEL_COLLECTOR_ENDPOINT=http://host.docker.internal:4317 -e FEATURE_FLAG_CLIENT=config -e AIRBYTE_VERSION=0.50.54 -e WORKER_JOB_ID=2 --cpus=2 --memory-reservation=1Gi --memory=2Gi airbyte/source-postgres:3.3.11 read --config source_config.json --catalog source_catalog.json --state input_state.json
2024-03-04 02:43:47 [46mplatform[0m > Writing messages to protocol version 0.2.0
2024-03-04 02:43:47 [46mplatform[0m > Reading messages from protocol version 0.2.0
2024-03-04 02:43:47 [46mplatform[0m > Reading messages from protocol version 0.2.0
2024-03-04 02:43:47 [46mplatform[0m > readFromSource: start
2024-03-04 02:43:47 [46mplatform[0m > Starting source heartbeat check. Will check every 1 minutes.
2024-03-04 02:43:47 [46mplatform[0m > processMessage: start
2024-03-04 02:43:47 [46mplatform[0m > writeToDestination: start
2024-03-04 02:43:47 [46mplatform[0m > readFromDestination: start
2024-03-04 02:43:52 [44msource[0m > 2024-03-04 02:43:52 [32mINFO[m i.a.i.s.p.PostgresSource(main):712 - starting source: class io.airbyte.integrations.source.postgres.PostgresSource
2024-03-04 02:43:52 [44msource[0m > 2024-03-04 02:43:52 [32mINFO[m i.a.c.i.b.IntegrationCliParser(parseOptions):126 - integration args: {read=null, catalog=source_catalog.json, state=input_state.json, config=source_config.json}
2024-03-04 02:43:52 [44msource[0m > 2024-03-04 02:43:52 [32mINFO[m i.a.c.i.b.IntegrationRunner(runInternal):132 - Running integration: io.airbyte.cdk.integrations.base.ssh.SshWrappedSource
2024-03-04 02:43:52 [44msource[0m > 2024-03-04 02:43:52 [32mINFO[m i.a.c.i.b.IntegrationRunner(runInternal):133 - Command: READ
2024-03-04 02:43:52 [44msource[0m > 2024-03-04 02:43:52 [32mINFO[m i.a.c.i.b.IntegrationRunner(runInternal):134 - Integration config: IntegrationConfig{command=READ, configPath='source_config.json', catalogPath='source_catalog.json', statePath='input_state.json'}
2024-03-04 02:43:53 [43mdestination[0m > 2024-03-04T02:43:53,068`[32mINFO[m`i.a.c.i.b.IntegrationCliParser(parseOptions):126 - integration args: {catalog=destination_catalog.json, write=null, config=destination_config.json}
2024-03-04 02:43:53 [43mdestination[0m > 2024-03-04T02:43:53,102`[32mINFO[m`i.a.c.i.b.IntegrationRunner(runInternal):132 - Running integration: io.airbyte.integrations.destination.bigquery.BigQueryDestination
2024-03-04 02:43:53 [43mdestination[0m > 2024-03-04T02:43:53,103`[32mINFO[m`i.a.c.i.b.IntegrationRunner(runInternal):133 - Command: WRITE
2024-03-04 02:43:53 [43mdestination[0m > 2024-03-04T02:43:53,105`[32mINFO[m`i.a.c.i.b.IntegrationRunner(runInternal):134 - Integration config: IntegrationConfig{command=WRITE, configPath='destination_config.json', catalogPath='destination_catalog.json', statePath='null'}
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword groups - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword order - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword group - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword airbyte_secret - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword always_show - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword display_type - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword min - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:53 [44msource[0m > 2024-03-04 02:43:53 [33mWARN[m c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword max - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:54 [43mdestination[0m > 2024-03-04T02:43:54,235`[33mWARN[m`c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword groups - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:54 [43mdestination[0m > 2024-03-04T02:43:54,239`[33mWARN[m`c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword group - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:54 [43mdestination[0m > 2024-03-04T02:43:54,244`[33mWARN[m`c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword order - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:54 [43mdestination[0m > 2024-03-04T02:43:54,250`[33mWARN[m`c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword display_type - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:54 [43mdestination[0m > 2024-03-04T02:43:54,286`[33mWARN[m`c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword airbyte_secret - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:54 [43mdestination[0m > 2024-03-04T02:43:54,288`[33mWARN[m`c.n.s.JsonMetaSchema(newValidator):278 - Unknown keyword always_show - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword
2024-03-04 02:43:54 [43mdestination[0m > 2024-03-04T02:43:54,537`[32mINFO[m`i.a.i.d.b.BigQueryUtils(getLoadingMethod):419 - Selected loading method is set to: STANDARD
2024-03-04 02:43:55 [44msource[0m > 2024-03-04 02:43:55 [32mINFO[m i.a.c.i.b.s.SshTunnel(getInstance):252 - Starting connection with method: NO_TUNNEL
2024-03-04 02:43:55 [44msource[0m > 2024-03-04 02:43:55 [32mINFO[m i.a.i.s.p.PostgresUtils(isCdc):70 - using CDC: true
2024-03-04 02:43:55 [43mdestination[0m > 2024-03-04T02:43:55,445`[33mWARN[m`i.a.i.d.b.BigQueryDestination(getSerializedMessageConsumer):259 - The "standard" upload mode is not performant, and is not recommended for production. Please use the GCS upload mode if you are syncing a large amount of data.
2024-03-04 02:43:55 [43mdestination[0m > 2024-03-04T02:43:55,446`[32mINFO[m`i.a.i.b.d.t.DefaultTyperDeduper(prepareTables):123 - Preparing tables
2024-03-04 02:43:55 [44msource[0m > 2024-03-04 02:43:55 [32mINFO[m i.a.c.i.s.r.s.StateManagerFactory(createStateManager):53 - Global state manager selected to manage state object with type GLOBAL.
2024-03-04 02:43:55 [44msource[0m > 2024-03-04 02:43:55 [32mINFO[m i.a.c.i.s.r.CdcStateManager(<init>):33 - Initialized CDC state with: io.airbyte.cdk.integrations.source.relationaldb.models.CdcState@327120c8[state={"[\"big-star-db\",{\"server\":\"big-star-db\"}]":"{\"transaction_id\":null,\"lsn\":38889184,\"txId\":743,\"ts_usec\":1709506742494130}"},additionalProperties={}]
2024-03-04 02:43:55 [44msource[0m > 2024-03-04 02:43:55 [32mINFO[m i.a.i.s.p.PostgresSource(toSslJdbcParamInternal):768 - DISABLED toSslJdbcParam disable
2024-03-04 02:43:55 [44msource[0m > 2024-03-04 02:43:55 [32mINFO[m c.z.h.HikariDataSource(<init>):79 - HikariPool-1 - Starting...
2024-03-04 02:43:55 [44msource[0m > 2024-03-04 02:43:55 [32mINFO[m c.z.h.HikariDataSource(<init>):81 - HikariPool-1 - Start completed.
2024-03-04 02:43:57 [44msource[0m > 2024-03-04 02:43:57 [32mINFO[m i.a.i.s.p.PostgresUtils(isCdc):70 - using CDC: true
2024-03-04 02:43:57 [44msource[0m > 2024-03-04 02:43:57 [32mINFO[m i.a.c.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 - Set initial fetch size: 10 rows
2024-03-04 02:43:57 [44msource[0m > 2024-03-04 02:43:57 [32mINFO[m i.a.i.s.p.PostgresCatalogHelper(getPublicizedTables):122 - For CDC, only tables in publication airbyte_publication will be included in the sync: [public.products, public.order_items, public.customers, public.orders]
2024-03-04 02:43:57 [44msource[0m > 2024-03-04 02:43:57 [32mINFO[m i.a.c.i.s.j.AbstractJdbcSource(logPreSyncDebugData):467 - Data source product recognized as PostgreSQL:15.3
2024-03-04 02:43:57 [44msource[0m > 2024-03-04 02:43:57 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):266 - Discovering indexes for schema "public", table "products"
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:57 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):268 - Index name: products_pkey, Column: product_id, Unique: true
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):266 - Discovering indexes for schema "public", table "order_items"
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):268 - Index name: order_items_pkey, Column: order_item_id, Unique: true
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):266 - Discovering indexes for schema "public", table "orders"
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):268 - Index name: orders_pkey, Column: order_id, Unique: true
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):266 - Discovering indexes for schema "public", table "customers"
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(logPreSyncDebugData):268 - Index name: customers_pkey, Column: customer_id, Unique: true
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.c.i.s.j.AbstractJdbcSource(discoverInternal):169 - Internal schemas to exclude: [catalog_history, information_schema, pg_catalog, pg_internal]
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.c.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 - Set initial fetch size: 10 rows
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresUtils(isCdc):70 - using CDC: true
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(getIncrementalIterators):475 - Using ctid + CDC
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(lambda$getReplicationSlot$4):403 - Attempting to find the named replication slot using the query: HikariProxyPreparedStatement@247795540 wrapping SELECT * FROM pg_replication_slots WHERE slot_name = 'airbyte_slot' AND plugin = 'pgoutput' AND database = 'big-star-db'
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.c.d.j.s.AdaptiveStreamingQueryConfig(initialize):31 - Set initial fetch size: 10 rows
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresUtils(getFirstRecordWaitTime):171 - First record waiting time: 1200 seconds
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresUtils(getSubsequentRecordWaitTime):183 - Subsequent record waiting time: 60 seconds
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.c.PostgresCdcCtidInitializer(cdcCtidIteratorsCombined):77 - First record waiting time: 1200 seconds
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.c.PostgresCdcCtidInitializer(cdcCtidIteratorsCombined):78 - Queue size: 10000
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.c.PostgresDebeziumStateUtil(format):238 - Initial Debezium state constructed: {"[\"big-star-db\",{\"server\":\"big-star-db\"}]":"{\"transaction_id\":null,\"lsn\":38889520,\"txId\":744,\"ts_usec\":1709520238703577}"}
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):78 - Should flush after sync: true
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [32mINFO[m i.a.i.s.p.PostgresSource(toSslJdbcParamInternal):768 - DISABLED toSslJdbcParam disable
2024-03-04 02:43:58 [44msource[0m > 2024-03-04 02:43:58 [33mWARN[m o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):315 - Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.d.c.CommonConnectorConfig(getSourceInfoStructMaker):1221 - Loading the custom source info struct maker plugin: io.debezium.connector.postgresql.PostgresSourceInfoStructMaker
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.c.PostgresDebeziumStateUtil(extractLsn):189 - Found previous partition offset PostgresPartition [sourcePartition={server=big-star-db}]: {transaction_id=null, lsn=38889184, txId=743, ts_usec=1709506742494130}
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.c.PostgresDebeziumStateUtil(parseSavedOffset):169 - Closing offsetStorageReader and fileOffsetBackingStore
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.c.PostgresDebeziumStateUtil(isSavedOffsetAfterReplicationSlotLSN):69 - Replication slot confirmed_flush_lsn : 38889184 Saved offset LSN : 38889184
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):78 - Should flush after sync: true
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.c.PostgresReplicationConnection(createConnection):44 - Creating a replication connection.
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.c.PostgresReplicationConnection(createConnection):47 - Validating replication connection.
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.c.PostgresCdcCtidInitializer(cdcCtidIteratorsCombined):178 - No streams will be synced via ctid
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.c.PostgresCdcTargetPosition(targetPosition):49 - identified target lsn: PgLsn{lsn=38889568}
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.PostgresUtils(shouldFlushAfterSync):78 - Should flush after sync: true
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.i.s.p.PostgresSource(toSslJdbcParamInternal):768 - DISABLED toSslJdbcParam disable
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.c.i.d.AirbyteDebeziumHandler(getIncrementalIterators):78 - Using CDC: true
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,695`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):26 - Assessing whether migration is necessary for stream products
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,695`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):26 - Assessing whether migration is necessary for stream order_items
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.a.c.i.d.AirbyteDebeziumHandler(getIncrementalIterators):79 - Using DBZ version: 2.4.0.Final
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,697`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):45 - Checking whether v1 raw table _airbyte_raw_products in dataset raw_data exists
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,697`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):45 - Checking whether v1 raw table _airbyte_raw_order_items in dataset raw_data exists
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,700`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):26 - Assessing whether migration is necessary for stream orders
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,701`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):26 - Assessing whether migration is necessary for stream customers
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,704`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):45 - Checking whether v1 raw table _airbyte_raw_orders in dataset raw_data exists
2024-03-04 02:43:59 [43mdestination[0m > 2024-03-04T02:43:59,708`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):45 - Checking whether v1 raw table _airbyte_raw_customers in dataset raw_data exists
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m o.a.k.c.c.AbstractConfig(logAll):369 - EmbeddedConfig values: 
2024-03-04 02:43:59 [44msource[0m > 	access.control.allow.methods = 
2024-03-04 02:43:59 [44msource[0m > 	access.control.allow.origin = 
2024-03-04 02:43:59 [44msource[0m > 	admin.listeners = null
2024-03-04 02:43:59 [44msource[0m > 	auto.include.jmx.reporter = true
2024-03-04 02:43:59 [44msource[0m > 	bootstrap.servers = [localhost:9092]
2024-03-04 02:43:59 [44msource[0m > 	client.dns.lookup = use_all_dns_ips
2024-03-04 02:43:59 [44msource[0m > 	config.providers = []
2024-03-04 02:43:59 [44msource[0m > 	connector.client.config.override.policy = All
2024-03-04 02:43:59 [44msource[0m > 	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
2024-03-04 02:43:59 [44msource[0m > 	key.converter = class org.apache.kafka.connect.json.JsonConverter
2024-03-04 02:43:59 [44msource[0m > 	listeners = [http://:8083]
2024-03-04 02:43:59 [44msource[0m > 	metric.reporters = []
2024-03-04 02:43:59 [44msource[0m > 	metrics.num.samples = 2
2024-03-04 02:43:59 [44msource[0m > 	metrics.recording.level = INFO
2024-03-04 02:43:59 [44msource[0m > 	metrics.sample.window.ms = 30000
2024-03-04 02:43:59 [44msource[0m > 	offset.flush.interval.ms = 1000
2024-03-04 02:43:59 [44msource[0m > 	offset.flush.timeout.ms = 5000
2024-03-04 02:43:59 [44msource[0m > 	offset.storage.file.filename = /tmp/cdc-state-offset3120367594674442446/offset.dat
2024-03-04 02:43:59 [44msource[0m > 	offset.storage.partitions = null
2024-03-04 02:43:59 [44msource[0m > 	offset.storage.replication.factor = null
2024-03-04 02:43:59 [44msource[0m > 	offset.storage.topic = 
2024-03-04 02:43:59 [44msource[0m > 	plugin.path = null
2024-03-04 02:43:59 [44msource[0m > 	response.http.headers.config = 
2024-03-04 02:43:59 [44msource[0m > 	rest.advertised.host.name = null
2024-03-04 02:43:59 [44msource[0m > 	rest.advertised.listener = null
2024-03-04 02:43:59 [44msource[0m > 	rest.advertised.port = null
2024-03-04 02:43:59 [44msource[0m > 	rest.extension.classes = []
2024-03-04 02:43:59 [44msource[0m > 	ssl.cipher.suites = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.client.auth = none
2024-03-04 02:43:59 [44msource[0m > 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
2024-03-04 02:43:59 [44msource[0m > 	ssl.endpoint.identification.algorithm = https
2024-03-04 02:43:59 [44msource[0m > 	ssl.engine.factory.class = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.key.password = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.keymanager.algorithm = SunX509
2024-03-04 02:43:59 [44msource[0m > 	ssl.keystore.certificate.chain = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.keystore.key = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.keystore.location = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.keystore.password = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.keystore.type = JKS
2024-03-04 02:43:59 [44msource[0m > 	ssl.protocol = TLSv1.3
2024-03-04 02:43:59 [44msource[0m > 	ssl.provider = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.secure.random.implementation = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.trustmanager.algorithm = PKIX
2024-03-04 02:43:59 [44msource[0m > 	ssl.truststore.certificates = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.truststore.location = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.truststore.password = null
2024-03-04 02:43:59 [44msource[0m > 	ssl.truststore.type = JKS
2024-03-04 02:43:59 [44msource[0m > 	task.shutdown.graceful.timeout.ms = 5000
2024-03-04 02:43:59 [44msource[0m > 	topic.creation.enable = true
2024-03-04 02:43:59 [44msource[0m > 	topic.tracking.allow.reset = true
2024-03-04 02:43:59 [44msource[0m > 	topic.tracking.enable = true
2024-03-04 02:43:59 [44msource[0m > 	value.converter = class org.apache.kafka.connect.json.JsonConverter
2024-03-04 02:43:59 [44msource[0m > 
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [33mWARN[m o.a.k.c.r.WorkerConfig(logPluginPathConfigProviderWarning):315 - Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [33mWARN[m i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1122 - Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.
2024-03-04 02:43:59 [44msource[0m > 2024-03-04 02:43:59 [32mINFO[m i.d.c.CommonConnectorConfig(getSourceInfoStructMaker):1221 - Loading the custom source info struct maker plugin: io.debezium.connector.postgresql.PostgresSourceInfoStructMaker
2024-03-04 02:44:00 [44msource[0m > 2024-03-04 02:44:00 [32mINFO[m i.d.c.p.PostgresConnector(testConnection):160 - Successfully tested connection for jdbc:postgresql://localhost:5432/big-star-db with user 'postgres'
2024-03-04 02:44:00 [43mdestination[0m > 2024-03-04T02:44:00,763`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):49 - Migration Info: Required for Sync mode: true, No existing v2 raw tables: false, A v1 raw table exists: false
2024-03-04 02:44:00 [43mdestination[0m > 2024-03-04T02:44:00,764`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):32 - No Migration Required for stream: products
2024-03-04 02:44:00 [43mdestination[0m > 2024-03-04T02:44:00,775`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):49 - Migration Info: Required for Sync mode: true, No existing v2 raw tables: false, A v1 raw table exists: false
2024-03-04 02:44:00 [43mdestination[0m > 2024-03-04T02:44:00,776`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):32 - No Migration Required for stream: orders
2024-03-04 02:44:00 [43mdestination[0m > 2024-03-04T02:44:00,795`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):49 - Migration Info: Required for Sync mode: true, No existing v2 raw tables: false, A v1 raw table exists: false
2024-03-04 02:44:00 [43mdestination[0m > 2024-03-04T02:44:00,797`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):32 - No Migration Required for stream: customers
2024-03-04 02:44:00 [44msource[0m > 2024-03-04 02:44:00 [32mINFO[m i.d.j.JdbcConnection(lambda$doClose$4):947 - Connection gracefully closed
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,020`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(shouldMigrate):49 - Migration Info: Required for Sync mode: true, No existing v2 raw tables: false, A v1 raw table exists: false
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,021`[32mINFO[m`i.a.i.b.d.t.BaseDestinationV1V2Migrator(migrateIfNecessary):32 - No Migration Required for stream: order_items
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [33mWARN[m i.d.c.p.PostgresConnectorConfig(validateFlushLsnSource):1122 - Property 'flush.lsn.source' is set to 'false', the LSN will not be flushed to the database source and WAL logs will not be cleared. User is expected to handle this outside Debezium.
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(start):136 - Starting PostgresConnectorTask with configuration:
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    connector.class = io.debezium.connector.postgresql.PostgresConnector
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    max.queue.size = 8192
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    slot.name = airbyte_slot
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    publication.name = airbyte_publication
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    database.sslmode = disable
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    topic.prefix = big-star-db
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    offset.storage.file.filename = /tmp/cdc-state-offset3120367594674442446/offset.dat
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    decimal.handling.mode = string
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    flush.lsn.source = false
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    converters = datetime
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    errors.retry.delay.initial.ms = 299
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    datetime.type = io.airbyte.integrations.source.postgres.cdc.PostgresConverter
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    value.converter = org.apache.kafka.connect.json.JsonConverter
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    key.converter = org.apache.kafka.connect.json.JsonConverter
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    publication.autocreate.mode = disabled
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    database.user = postgres
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    database.dbname = big-star-db
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    offset.storage = org.apache.kafka.connect.storage.FileOffsetBackingStore
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    max.queue.size.in.bytes = 268435456
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    errors.retry.delay.max.ms = 300
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    offset.flush.timeout.ms = 5000
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    heartbeat.interval.ms = 10000
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    column.include.list = \Qpublic.products\E\.(\Qname\E|\Qprice\E|\Qrating\E|\Qcategory\E|\Qcollection\E|\Qproduct_id\E|\Q_ab_cdc_lsn\E|\Qavailability\E|\Q_ab_cdc_deleted_at\E|\Q_ab_cdc_updated_at\E),\Qpublic.order_items\E\.(\Qorder_id\E|\Qproduct_id\E|\Q_ab_cdc_lsn\E|\Qorder_item_id\E|\Qproduct_price\E|\Q_ab_cdc_deleted_at\E|\Q_ab_cdc_updated_at\E),\Qpublic.orders\E\.(\Qstatus\E|\Qorder_id\E|\Q_ab_cdc_lsn\E|\Qcustomer_id\E|\Qorder_approved_at\E|\Q_ab_cdc_deleted_at\E|\Q_ab_cdc_updated_at\E|\Qorder_delivered_at\E|\Qorder_purchased_at\E),\Qpublic.customers\E\.(\Qcity\E|\Qemail\E|\Qgender\E|\Qcountry\E|\Qlast_name\E|\Qfirst_name\E|\Qip_address\E|\Q_ab_cdc_lsn\E|\Qcustomer_id\E|\Q_ab_cdc_deleted_at\E|\Q_ab_cdc_updated_at\E)
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    plugin.name = pgoutput
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    database.port = 5432
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    offset.flush.interval.ms = 1000
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    key.converter.schemas.enable = false
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    include.unknown.datatypes = true
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    errors.max.retries = 0
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    database.hostname = localhost
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    database.password = ********
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    value.converter.schemas.enable = false
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    name = big-star-db
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    max.batch.size = 2048
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    table.include.list = \Qpublic.products\E,\Qpublic.order_items\E,\Qpublic.orders\E,\Qpublic.customers\E
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.c.BaseSourceTask(lambda$start$0):138 -    snapshot.mode = initial
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.CommonConnectorConfig(getSourceInfoStructMaker):1221 - Loading the custom source info struct maker plugin: io.debezium.connector.postgresql.PostgresSourceInfoStructMaker
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.c.CommonConnectorConfig(getTopicNamingStrategy):973 - Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,093`[32mINFO[m`i.a.i.d.b.t.BigQueryV2TableMigrator(migrateIfNecessary):76 - No Data column Migration Required for stream raw_data_raw__stream_orders
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,121`[32mINFO[m`i.a.i.d.b.t.BigQueryV2TableMigrator(migrateIfNecessary):76 - No Data column Migration Required for stream raw_data_raw__stream_products
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,154`[32mINFO[m`i.a.i.d.b.t.BigQueryV2TableMigrator(migrateIfNecessary):76 - No Data column Migration Required for stream raw_data_raw__stream_customers
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,259`[32mINFO[m`i.a.i.b.d.t.DefaultTyperDeduper(lambda$prepareTablesFuture$3):146 - Final Table exists for stream products
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,271`[32mINFO[m`i.a.i.d.b.t.BigQuerySqlGenerator(existingSchemaMatchesStreamConfig):273 - Alter Table Report [] [] []; Clustering true; Partitioning true
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,279`[32mINFO[m`i.a.i.b.d.t.DefaultTyperDeduper(lambda$prepareTablesFuture$3):146 - Final Table exists for stream orders
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,281`[32mINFO[m`i.a.i.d.b.t.BigQuerySqlGenerator(existingSchemaMatchesStreamConfig):273 - Alter Table Report [] [] []; Clustering true; Partitioning true
2024-03-04 02:44:01 [44msource[0m > 2024-03-04 02:44:01 [32mINFO[m i.d.j.JdbcConnection(lambda$doClose$4):947 - Connection gracefully closed
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,364`[32mINFO[m`i.a.i.d.b.t.BigQueryV2TableMigrator(migrateIfNecessary):76 - No Data column Migration Required for stream raw_data_raw__stream_order_items
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,404`[32mINFO[m`i.a.i.b.d.t.DefaultTyperDeduper(lambda$prepareTablesFuture$3):146 - Final Table exists for stream customers
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,406`[32mINFO[m`i.a.i.d.b.t.BigQuerySqlGenerator(existingSchemaMatchesStreamConfig):273 - Alter Table Report [] [] []; Clustering true; Partitioning true
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,557`[32mINFO[m`i.a.i.b.d.t.DefaultTyperDeduper(lambda$prepareTablesFuture$3):146 - Final Table exists for stream order_items
2024-03-04 02:44:01 [43mdestination[0m > 2024-03-04T02:44:01,558`[32mINFO[m`i.a.i.d.b.t.BigQuerySqlGenerator(existingSchemaMatchesStreamConfig):273 - Alter Table Report [] [] []; Clustering true; Partitioning true
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.c.c.BaseSourceTask(getPreviousOffsets):376 - Found previous partition offset PostgresPartition [sourcePartition={server=big-star-db}]: {transaction_id=null, lsn=38889184, txId=743, ts_usec=1709506742494130}
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.c.p.PostgresConnectorTask(start):120 - user 'postgres' connected to database 'big-star-db' on PostgreSQL 15.3 on aarch64-unknown-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r10) 12.2.1 20220924, 64-bit with roles:
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_database_owner' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_checkpoint' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_read_all_data' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_write_all_data' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
2024-03-04 02:44:02 [44msource[0m > 	role 'postgres' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):325 - Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/25166E0}, catalogXmin=743]
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.c.p.PostgresConnectorTask(start):134 - Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='big-star-db'db='big-star-db', lsn=LSN{0/25166E0}, txId=743, timestamp=2024-03-03T22:59:02.494130Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.u.Threads(threadFactory):271 - Requested thread factory for connector PostgresConnector, id = big-star-db named = SignalProcessor
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.u.Threads(threadFactory):271 - Requested thread factory for connector PostgresConnector, id = big-star-db named = change-event-source-coordinator
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.u.Threads(threadFactory):271 - Requested thread factory for connector PostgresConnector, id = big-star-db named = blocking-snapshot
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.u.Threads$3(newThread):288 - Creating thread debezium-postgresconnector-big-star-db-change-event-source-coordinator
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.p.ChangeEventSourceCoordinator(lambda$start$0):131 - Metrics registered
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.p.ChangeEventSourceCoordinator(lambda$start$0):134 - Context created
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.p.s.SignalProcessor(start):105 - SignalProcessor started. Scheduling it every 5000ms
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.u.Threads$3(newThread):288 - Creating thread debezium-postgresconnector-big-star-db-SignalProcessor
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.c.p.s.InitialSnapshotter(shouldSnapshot):42 - Previous snapshot has completed successfully, streaming logical changes from last known position
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.c.p.PostgresSnapshotChangeEventSource(getSnapshottingTask):76 - According to the connector configuration no snapshot will be executed
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.p.ChangeEventSourceCoordinator(doSnapshot):254 - Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='big-star-db'db='big-star-db', lsn=LSN{0/25166E0}, txId=743, timestamp=2024-03-03T22:59:02.494130Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=false, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]]
2024-03-04 02:44:02 [44msource[0m > 2024-03-04 02:44:02 [32mINFO[m i.d.p.ChangeEventSourceCoordinator(streamingConnected):423 - Connected metrics set to 'true'
2024-03-04 02:44:02 [43mdestination[0m > 2024-03-04T02:44:02,785`[32mINFO[m`i.a.c.i.d.b.BufferManager(<init>):53 - Max 'memory' available for buffer allocation 768 MB
2024-03-04 02:44:02 [43mdestination[0m > 2024-03-04T02:44:02,809`[32mINFO[m`i.a.c.i.d.b.BufferManager(printQueueInfo):118 - [ASYNC QUEUE INFO] Global: max: 768 MB, allocated: 10 MB (10.0 MB), % used: 0.013020833333333334 | State Manager memory usage: Allocated: 10 MB, Used: 0 bytes, percentage Used 0.000000
2024-03-04 02:44:02 [43mdestination[0m > 2024-03-04T02:44:02,811`[32mINFO[m`i.a.c.i.d.FlushWorkers(start):95 - Start async buffer supervisor
2024-03-04 02:44:02 [43mdestination[0m > 2024-03-04T02:44:02,816`[32mINFO[m`i.a.c.i.d.AsyncStreamConsumer(start):138 - class io.airbyte.cdk.integrations.destination_async.AsyncStreamConsumer started.
2024-03-04 02:44:02 [43mdestination[0m > 2024-03-04T02:44:02,816`[32mINFO[m`i.a.c.i.d.FlushWorkers(printWorkerInfo):143 - [ASYNC WORKER INFO] Pool queue size: 0, Active threads: 0
2024-03-04 02:44:02 [43mdestination[0m > 2024-03-04T02:44:02,836`[32mINFO[m`i.a.i.d.b.BigQueryUtils(getLoadingMethod):419 - Selected loading method is set to: STANDARD
2024-03-04 02:44:03 [43mdestination[0m > 2024-03-04T02:44:03,278`[32mINFO[m`i.a.i.d.b.u.BigQueryUploaderFactory(getBigQueryDirectUploader):88 - Will write raw data to GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, tableId=raw_data_raw__stream_products}} with schema Schema{fields=[Field{name=_airbyte_raw_id, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_extracted_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_loaded_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_data, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}]}
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.orders' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.customers' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.order_items' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.products' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.p.ChangeEventSourceCoordinator(streamEvents):271 - Starting streaming
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.c.p.PostgresStreamingChangeEventSource(execute):141 - Retrieved latest position from stored offset 'LSN{0/25166E0}'
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.c.p.c.WalPositionLocator(<init>):48 - Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/25166E0}'
2024-03-04 02:44:03 [44msource[0m > 2024-03-04 02:44:03 [32mINFO[m i.d.c.p.c.PostgresReplicationConnection(initPublication):150 - Initializing PgOutput logical decoder publication
2024-03-04 02:44:03 [43mdestination[0m > 2024-03-04T02:44:03,674`[32mINFO[m`i.a.i.d.b.BigQueryUtils(getLoadingMethod):419 - Selected loading method is set to: STANDARD
2024-03-04 02:44:04 [43mdestination[0m > 2024-03-04T02:44:04,128`[32mINFO[m`i.a.i.d.b.u.BigQueryUploaderFactory(getBigQueryDirectUploader):88 - Will write raw data to GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, tableId=raw_data_raw__stream_order_items}} with schema Schema{fields=[Field{name=_airbyte_raw_id, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_extracted_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_loaded_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_data, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}]}
2024-03-04 02:44:04 [43mdestination[0m > 2024-03-04T02:44:04,404`[32mINFO[m`i.a.i.d.b.BigQueryUtils(getLoadingMethod):419 - Selected loading method is set to: STANDARD
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.c.p.c.PostgresConnection(readReplicationSlotInfo):325 - Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/25166E0}, catalogXmin=743]
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.j.JdbcConnection(lambda$doClose$4):947 - Connection gracefully closed
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.u.Threads(threadFactory):271 - Requested thread factory for connector PostgresConnector, id = big-star-db named = keep-alive
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.u.Threads$3(newThread):288 - Creating thread debezium-postgresconnector-big-star-db-keep-alive
2024-03-04 02:44:04 [43mdestination[0m > 2024-03-04T02:44:04,721`[32mINFO[m`i.a.i.d.b.u.BigQueryUploaderFactory(getBigQueryDirectUploader):88 - Will write raw data to GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, tableId=raw_data_raw__stream_orders}} with schema Schema{fields=[Field{name=_airbyte_raw_id, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_extracted_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_loaded_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_data, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}]}
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.orders' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.customers' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.order_items' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.c.p.PostgresSchema(printReplicaIdentityInfo):100 - REPLICA IDENTITY for 'public.products' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns
2024-03-04 02:44:04 [44msource[0m > 2024-03-04 02:44:04 [32mINFO[m i.d.c.p.PostgresStreamingChangeEventSource(searchWalPosition):341 - Searching for WAL resume position
2024-03-04 02:44:05 [43mdestination[0m > 2024-03-04T02:44:05,069`[32mINFO[m`i.a.i.d.b.BigQueryUtils(getLoadingMethod):419 - Selected loading method is set to: STANDARD
2024-03-04 02:44:05 [43mdestination[0m > 2024-03-04T02:44:05,430`[32mINFO[m`i.a.i.d.b.u.BigQueryUploaderFactory(getBigQueryDirectUploader):88 - Will write raw data to GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, tableId=raw_data_raw__stream_customers}} with schema Schema{fields=[Field{name=_airbyte_raw_id, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_extracted_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_loaded_at, type=TIMESTAMP, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}, Field{name=_airbyte_data, type=STRING, mode=null, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null, rangeElementType=null}]}
2024-03-04 02:44:05 [43mdestination[0m > 2024-03-04T02:44:05,866`[32mINFO[m`i.a.i.d.b.u.AbstractBigQueryUploader(createRawTable):131 - Found raw table GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, projectId=big-star-collectibles-416120, tableId=raw_data_raw__stream_customers}}.
2024-03-04 02:44:06 [43mdestination[0m > 2024-03-04T02:44:06,021`[32mINFO[m`i.a.i.d.b.u.AbstractBigQueryUploader(createRawTable):131 - Found raw table GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, projectId=big-star-collectibles-416120, tableId=raw_data_raw__stream_order_items}}.
2024-03-04 02:44:06 [43mdestination[0m > 2024-03-04T02:44:06,168`[32mINFO[m`i.a.i.d.b.u.AbstractBigQueryUploader(createRawTable):131 - Found raw table GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, projectId=big-star-collectibles-416120, tableId=raw_data_raw__stream_orders}}.
2024-03-04 02:44:06 [43mdestination[0m > 2024-03-04T02:44:06,290`[32mINFO[m`i.a.i.d.b.u.AbstractBigQueryUploader(createRawTable):131 - Found raw table GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=airbyte_internal, projectId=big-star-collectibles-416120, tableId=raw_data_raw__stream_products}}.
2024-03-04 02:45:02 [43mdestination[0m > 2024-03-04T02:45:02,804`[32mINFO[m`i.a.c.i.d.b.BufferManager(printQueueInfo):118 - [ASYNC QUEUE INFO] Global: max: 768 MB, allocated: 10 MB (10.0 MB), % used: 0.013020833333333334 | State Manager memory usage: Allocated: 10 MB, Used: 0 bytes, percentage Used 0.000000
2024-03-04 02:45:02 [43mdestination[0m > 2024-03-04T02:45:02,815`[32mINFO[m`i.a.c.i.d.FlushWorkers(printWorkerInfo):143 - [ASYNC WORKER INFO] Pool queue size: 0, Active threads: 0
2024-03-04 02:46:02 [43mdestination[0m > 2024-03-04T02:46:02,801`[32mINFO[m`i.a.c.i.d.b.BufferManager(printQueueInfo):118 - [ASYNC QUEUE INFO] Global: max: 768 MB, allocated: 10 MB (10.0 MB), % used: 0.013020833333333334 | State Manager memory usage: Allocated: 10 MB, Used: 0 bytes, percentage Used 0.000000
2024-03-04 02:46:02 [43mdestination[0m > 2024-03-04T02:46:02,814`[32mINFO[m`i.a.c.i.d.FlushWorkers(printWorkerInfo):143 - [ASYNC WORKER INFO] Pool queue size: 0, Active threads: 0
